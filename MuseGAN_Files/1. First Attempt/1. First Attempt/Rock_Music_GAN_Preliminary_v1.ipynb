{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb898fce",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "861e2ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: music21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (6.7.1)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (8.7.0)\n",
      "Requirement already satisfied: webcolors in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (1.11.1)\n",
      "Requirement already satisfied: chardet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (3.0.4)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow \n",
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4292cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ca0214",
   "metadata": {},
   "source": [
    "# 1. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a43f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bbd3c6a",
   "metadata": {},
   "source": [
    "We will begin by creating the dataset for the classical music image files \n",
    "\n",
    "In future iterations, we may want to consider analyzing colored images to extract more infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b447b1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rock00065.png', 'rock00051.png', 'rock00042.png', 'rock00090.png', 'rock00021.png', 'rock00039.png', 'rock00074.png', 'rock00059.png', 'rock00028.png', 'rock00099.png', 'rock00035.png', 'rock00025.png', 'rock00078.png', 'rock00055.png', 'rock00024.png', 'rock00044.png', 'rock00006.png', 'rock00000.png', 'rock00007.png', 'rock00062.png', 'rock00003.png', 'rock00032.png', 'rock00058.png', 'rock00038.png', 'rock00011.png', 'rock00069.png', 'rock00009.png', 'rock00079.png', 'rock00016.png', 'rock00076.png', 'rock00071.png', 'rock00056.png', 'rock00045.png', 'rock00018.png', 'rock00046.png', 'rock00053.png', 'rock00026.png', 'rock00023.png', 'rock00067.png', 'rock00041.png', 'rock00013.png', 'rock00082.png', 'rock00010.png', 'rock00073.png', 'rock00084.png', 'rock00047.png', 'rock00012.png', 'rock00089.png', 'rock00001.png', 'rock00087.png', 'rock00054.png', 'rock00027.png', 'rock00052.png', 'rock00031.png', 'rock00005.png', 'rock00080.png', 'rock00077.png', 'rock00072.png', 'rock00083.png', 'rock00017.png', 'rock00098.png', 'rock00019.png', 'rock00037.png', 'rock00034.png', 'rock00091.png', 'rock00064.png', 'rock00088.png', 'rock00061.png', 'rock00097.png', 'rock00093.png', 'rock00030.png', 'rock00033.png', 'rock00029.png', 'rock00060.png', 'rock00094.png', 'rock00063.png', 'rock00057.png', 'rock00092.png', 'rock00040.png', 'rock00066.png', 'rock00043.png', 'rock00036.png', 'rock00002.png', 'rock00022.png', 'rock00008.png', 'rock00015.png', 'rock00049.png', 'rock00048.png', 'rock00081.png', 'rock00095.png', 'rock00068.png', 'rock00096.png', 'rock00020.png', 'rock00075.png', 'rock00050.png', 'rock00070.png', 'rock00086.png', 'rock00004.png', 'rock00014.png', 'rock00085.png']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/Image files/Rock - images'\n",
    "\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "print(img_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "107b6ef3",
   "metadata": {},
   "source": [
    "The images get converted to black and white, so the pixel values are either 0 (black) or 1 (white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73151ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_images(img_list,path):\n",
    "    pixels = []\n",
    "    imgs = []\n",
    "    for i in range(len(img_list)):\n",
    "        if 'png' in img_list[i]:\n",
    "            try:\n",
    "                img = Image.open(path+'/'+img_list[i],'r')\n",
    "                img = img.convert('1')\n",
    "                img = img.resize((106, 106)) # added by me (turns them into smaller images)\n",
    "                pix = np.array(img.getdata())\n",
    "                pix = pix.astype('float32')\n",
    "                pix /= 255.0\n",
    "                pixels.append(pix.reshape(106, 106, 1))\n",
    "                imgs.append(img)\n",
    "            except:\n",
    "                pass\n",
    "    return np.array(pixels),imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c66c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(pix_list):\n",
    "    array = np.array(pix_list.reshape(106,106), dtype=np.uint8)\n",
    "    new_image = Image.fromarray(array)\n",
    "    new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b22515",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels,imgs = access_images(img_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d83e73fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 106, 106, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67eed691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAABqAQAAAAB8Wvk6AAAC6klEQVR4nNWUT2jcRRTHP/M6u53Utf4SY42lpaPUGPFSsWCRaGbDHjbQQ5QehCDGPwcPBT1IBa11IxFyqDcRD4rxUPRYPPmnwmz0UIJIGi9FCi5hhYj/thLbXzaz+zzsJtqDd/tun5nvvPd9b4Yxyr+iLtwQNwVaNt0O6P/FlYC/ERv/LbY7C5YOCOrBgEtJQdCGQSHfOXtoW93D9d4AUh/zHAjb4t5e3Mbc4YCQbYuZxVDPA6AJsJESrqhRIMOnSXKSgJBarnGOACnviY3zNSoGNKKbwCSUKkNoRNsBIDjCLo1CtwFIPEajA2j+T/MaBUre4Qmh15GktXZjcuFitUhffNiJtdagURDnmvnu084cegbQPOAJNriARjRZ4KN+ZjT3eBzV+T4GWCyDdb264JpLmNncg0BL8iuL3PL+S2sgkJ0h/nZ8o7TS7dtwNQJuXy8VWDdHieGCRoExUvZhJbcbCgIjrlrlwnh6MgGaZ4ytvlD23mQa0dwAwU5a27Mx4fxAtN1MioAmW7PlObDypkZ0s+BrRc/3PD6oEW0PzFmIhntHNKJpD0MMBNesTWsU0jX/u79ezg/KeRBkfyNrMoEuBRBklFcrsVaaHTP9jrIYrKNvY5Zr95hxTHewP42zvlpxu0avgoWWvMEntz2yJ10GgYuFP7qX/Na3K72HlBgK3fC1X6uCwFPXW+tzv56oZ1+ChfsYfvaUPW327wWjnXnz1U+dZlp+Yn2rjubHGF0k2unbD2hE2/PrWbmOLfVcdd86N7p74u3m86kAaHv58N5i8Le+44NGtJ0tEqhO9a9786wd5wAmDGYaBY7evXxiilprIwPBLswcOf8zP67MTIOwdcr8UPnz5PrAd2dAKCxx5POVy9+8tvoyCGn5uWyi88HDCw8mEDAXug+Vhh9wr4yARQ/+8umlfcOPXv2sAYKd+evjypWjd7VePA5oW7w8PXhHmH8PjZbu6sm1qfu/eOz1O98Fc/N/uX8Dq0kxX51FljEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=106x106 at 0x7F9318D4B4E0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954353cd",
   "metadata": {},
   "source": [
    "# 2. Define discriminator and generator  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "fbb3fcdb",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb14255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape = (106,106,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate = 0.0002, beta_1=0.5) # lr was deprecated\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91cb6be5",
   "metadata": {},
   "source": [
    "Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22a2602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 53 * 53\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((53, 53, 128)))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2DTranspose(1024, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2D(1, (7,7) , padding='same',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2278f54",
   "metadata": {},
   "source": [
    "# 3. Put them together to define the full GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c13868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde1453",
   "metadata": {},
   "source": [
    "# 4. Define functions to generate fake and real points"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d10f8148",
   "metadata": {},
   "source": [
    "The latent_points work as the input of the generator while the fake and real samples are to train and test the discriminator.\n",
    "\n",
    "The following are: \n",
    "\n",
    "- Generate real samples: selects a datapoint from array\n",
    "\n",
    "- Generate latent points: generatres a random array of a give size (to be inputed into generator)\n",
    "\n",
    "- Generate fake samples: takes random data and generates a picture w/ generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d771a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5fe083",
   "metadata": {},
   "source": [
    "# 5. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24aaf2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 is way too many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c70a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=15, n_batch=10):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "#         if (i+1) % 10 == 0:\n",
    "#             print(\"Iteration: \", i)\n",
    "#             summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc293632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 106, 106, 1)\n",
      ">1, 1/10, d=0.512, g=0.680\n",
      ">1, 2/10, d=0.447, g=0.742\n",
      ">1, 3/10, d=0.370, g=0.701\n",
      ">1, 4/10, d=0.148, g=0.701\n",
      ">1, 5/10, d=0.116, g=0.705\n",
      ">1, 6/10, d=0.102, g=0.681\n",
      ">1, 7/10, d=0.048, g=0.686\n",
      ">1, 8/10, d=0.221, g=0.630\n",
      ">1, 9/10, d=0.125, g=0.607\n",
      ">1, 10/10, d=0.061, g=0.604\n",
      ">2, 1/10, d=0.031, g=0.581\n",
      ">2, 2/10, d=0.027, g=0.549\n",
      ">2, 3/10, d=0.017, g=0.534\n",
      ">2, 4/10, d=0.045, g=0.524\n",
      ">2, 5/10, d=0.023, g=0.513\n",
      ">2, 6/10, d=0.031, g=0.503\n",
      ">2, 7/10, d=0.023, g=0.500\n",
      ">2, 8/10, d=0.012, g=0.479\n",
      ">2, 9/10, d=0.076, g=0.441\n",
      ">2, 10/10, d=0.175, g=0.440\n",
      ">3, 1/10, d=0.425, g=0.443\n",
      ">3, 2/10, d=0.431, g=0.510\n",
      ">3, 3/10, d=0.235, g=0.697\n",
      ">3, 4/10, d=0.326, g=0.738\n",
      ">3, 5/10, d=0.587, g=0.505\n",
      ">3, 6/10, d=0.104, g=0.564\n",
      ">3, 7/10, d=0.345, g=0.497\n",
      ">3, 8/10, d=0.246, g=0.565\n",
      ">3, 9/10, d=0.184, g=0.462\n",
      ">3, 10/10, d=0.109, g=0.575\n",
      ">4, 1/10, d=0.060, g=0.497\n",
      ">4, 2/10, d=0.203, g=0.495\n",
      ">4, 3/10, d=0.110, g=0.454\n",
      ">4, 4/10, d=0.128, g=0.492\n",
      ">4, 5/10, d=0.106, g=0.410\n",
      ">4, 6/10, d=0.076, g=0.438\n",
      ">4, 7/10, d=0.157, g=0.533\n",
      ">4, 8/10, d=0.102, g=0.448\n",
      ">4, 9/10, d=0.042, g=0.493\n",
      ">4, 10/10, d=0.058, g=0.491\n",
      ">5, 1/10, d=0.093, g=0.467\n",
      ">5, 2/10, d=0.070, g=0.499\n",
      ">5, 3/10, d=0.079, g=0.505\n",
      ">5, 4/10, d=0.060, g=0.492\n",
      ">5, 5/10, d=0.112, g=0.419\n",
      ">5, 6/10, d=0.037, g=0.462\n",
      ">5, 7/10, d=0.132, g=0.437\n",
      ">5, 8/10, d=0.034, g=0.451\n",
      ">5, 9/10, d=0.055, g=0.453\n",
      ">5, 10/10, d=0.046, g=0.396\n",
      ">6, 1/10, d=0.044, g=0.433\n",
      ">6, 2/10, d=0.067, g=0.399\n",
      ">6, 3/10, d=0.072, g=0.401\n",
      ">6, 4/10, d=0.069, g=0.489\n",
      ">6, 5/10, d=0.034, g=0.472\n",
      ">6, 6/10, d=0.023, g=0.396\n",
      ">6, 7/10, d=0.037, g=0.418\n",
      ">6, 8/10, d=0.074, g=0.409\n",
      ">6, 9/10, d=0.111, g=0.488\n",
      ">6, 10/10, d=0.023, g=0.423\n",
      ">7, 1/10, d=0.049, g=0.417\n",
      ">7, 2/10, d=0.018, g=0.462\n",
      ">7, 3/10, d=0.138, g=0.372\n",
      ">7, 4/10, d=0.044, g=0.334\n",
      ">7, 5/10, d=0.028, g=0.482\n",
      ">7, 6/10, d=0.039, g=0.405\n",
      ">7, 7/10, d=0.061, g=0.476\n",
      ">7, 8/10, d=0.051, g=0.467\n",
      ">7, 9/10, d=0.045, g=0.532\n",
      ">7, 10/10, d=0.071, g=0.444\n",
      ">8, 1/10, d=0.063, g=0.380\n",
      ">8, 2/10, d=0.031, g=0.439\n",
      ">8, 3/10, d=0.065, g=0.391\n",
      ">8, 4/10, d=0.037, g=0.464\n",
      ">8, 5/10, d=0.139, g=0.516\n",
      ">8, 6/10, d=0.018, g=0.483\n",
      ">8, 7/10, d=0.024, g=0.534\n",
      ">8, 8/10, d=0.022, g=0.412\n",
      ">8, 9/10, d=0.007, g=0.473\n",
      ">8, 10/10, d=0.023, g=0.447\n",
      ">9, 1/10, d=0.019, g=0.495\n",
      ">9, 2/10, d=0.011, g=0.452\n",
      ">9, 3/10, d=0.026, g=0.492\n",
      ">9, 4/10, d=0.042, g=0.432\n",
      ">9, 5/10, d=0.042, g=0.431\n",
      ">9, 6/10, d=0.015, g=0.459\n",
      ">9, 7/10, d=0.008, g=0.469\n",
      ">9, 8/10, d=0.057, g=0.410\n",
      ">9, 9/10, d=0.019, g=0.429\n",
      ">9, 10/10, d=0.038, g=0.411\n",
      ">10, 1/10, d=0.033, g=0.423\n",
      ">10, 2/10, d=0.021, g=0.451\n",
      ">10, 3/10, d=0.021, g=0.434\n",
      ">10, 4/10, d=0.055, g=0.440\n",
      ">10, 5/10, d=0.083, g=0.378\n",
      ">10, 6/10, d=0.019, g=0.479\n",
      ">10, 7/10, d=0.026, g=0.382\n",
      ">10, 8/10, d=0.021, g=0.446\n",
      ">10, 9/10, d=0.029, g=0.397\n",
      ">10, 10/10, d=0.019, g=0.406\n",
      ">11, 1/10, d=0.026, g=0.432\n",
      ">11, 2/10, d=0.017, g=0.404\n",
      ">11, 3/10, d=0.017, g=0.386\n",
      ">11, 4/10, d=0.037, g=0.385\n",
      ">11, 5/10, d=0.016, g=0.353\n",
      ">11, 6/10, d=0.020, g=0.369\n",
      ">11, 7/10, d=0.016, g=0.387\n",
      ">11, 8/10, d=0.025, g=0.385\n",
      ">11, 9/10, d=0.017, g=0.384\n",
      ">11, 10/10, d=0.088, g=0.363\n",
      ">12, 1/10, d=0.043, g=0.373\n",
      ">12, 2/10, d=0.053, g=0.394\n",
      ">12, 3/10, d=0.032, g=0.350\n",
      ">12, 4/10, d=0.028, g=0.346\n",
      ">12, 5/10, d=0.026, g=0.358\n",
      ">12, 6/10, d=0.021, g=0.298\n",
      ">12, 7/10, d=0.034, g=0.309\n",
      ">12, 8/10, d=0.086, g=0.283\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(pixels.shape)\n",
    "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f283a62",
   "metadata": {},
   "source": [
    "# 6. Use newly trained generator to generate new song images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94566689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1906f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 0\n",
    "\n",
    "while number_images < 10: \n",
    "    latent_points = generate_latent_points(latent_dim,1)\n",
    "    X = g_model.predict(latent_points)\n",
    "    # A one in the discriminator means it thinks it is real\n",
    "    prediction = np.round(d_model.predict(X)[0][0])\n",
    "    \n",
    "    if prediction == 1: \n",
    "        arr = np.array(X.reshape(106,106),dtype = np.uint8);\n",
    "        arr*= 255;\n",
    "        new_image = Image.fromarray(arr,'L')\n",
    "        plt.figure(); \n",
    "        plt.imshow(new_image);\n",
    "        new_image.save('04_16_attempt_1_rock_music_15_epochs_OutputNumber_' + str(number_images) + '.png')\n",
    "        number_images += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a672f35",
   "metadata": {},
   "source": [
    "# 7. Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87e9069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: 04-16-classical-music-generator/assets\n"
     ]
    }
   ],
   "source": [
    "g_model.save('04-16-classical-music-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da01e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "g_model.save('04-16-classical-music-generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0f334a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 04-16-classical-music-discriminator/assets\n"
     ]
    }
   ],
   "source": [
    "d_model.save('04-16-classical-music-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dd219935",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-16-classical-music-discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9329e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 04-16-classical-music-full-gan/assets\n"
     ]
    }
   ],
   "source": [
    "gan_model.save('04-16-classical-music-full-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e66865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-16-classical-music-full-gan.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439dde79",
   "metadata": {},
   "source": [
    "# 8. Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "162ab234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "077e2467",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image2midi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9a85fc028daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'04_16_attempt_1_classical_music_10_epochs_OutputNumber_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image2midi' is not defined"
     ]
    }
   ],
   "source": [
    "ex = 0; \n",
    "image2midi('04_16_attempt_1_classical_music_10_epochs_OutputNumber_' + str(ex) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eaa93b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
