{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56aaeb3e",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46e6c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "     |████████████████████████████████| 458.3 MB 15 kB/s               \n",
      "\u001b[?25hCollecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 68.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 75.6 MB/s            \n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 118.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.44.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "     |████████████████████████████████| 4.3 MB 37.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 781 kB/s             \n",
      "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 59.5 MB/s            \n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     |████████████████████████████████| 65 kB 7.5 MB/s              \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 118.0 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 64.3 MB/s            \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 12.8 MB/s             \n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 62.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 71.8 MB/s            \n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     |████████████████████████████████| 151 kB 118.1 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=1a7d5279f3b5add08554f79c65d25b5d14881290caa63f3ae5e0fd37539cedab\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=a07a42b42644f9c823c30886c4c7d8b71664dc1c55ddb3b860005a8af2efe060\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: typing-extensions, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.0\n",
      "    Uninstalling importlib-metadata-3.7.0:\n",
      "      Successfully uninstalled importlib-metadata-3.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.12.2 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "astroid 2.9.0 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.24.25 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.44.0 importlib-metadata-4.8.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3\n",
      "Collecting music21\n",
      "  Downloading music21-6.7.1.tar.gz (19.2 MB)\n",
      "     |████████████████████████████████| 19.2 MB 32.6 MB/s eta 0:00:01     |████████████████████████████████| 19.2 MB 32.6 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: chardet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (3.0.4)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (1.0.1)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (8.7.0)\n",
      "Collecting webcolors\n",
      "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
      "Building wheels for collected packages: music21\n",
      "  Building wheel for music21 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for music21: filename=music21-6.7.1-py3-none-any.whl size=21941692 sha256=909d22749865b9ae063f5fbd6c27c8ae47e1da3bddc41d4fd684e334e5899a74\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/66/b8/68/c374fb21ae1e0faea5b8bc7e537b8e89e91da904edc5c3e224\n",
      "Successfully built music21\n",
      "Installing collected packages: webcolors, music21\n",
      "Successfully installed music21-6.7.1 webcolors-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow \n",
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f72468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3614efce",
   "metadata": {},
   "source": [
    "# 1. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "520f34a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "689b6c5d",
   "metadata": {},
   "source": [
    "We will begin by creating the dataset for the classical music image files \n",
    "\n",
    "In future iterations, we may want to consider analyzing colored images to extract more infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37486982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jazz00096.png', 'jazz00091.png', 'jazz00060.png', 'jazz00009.png', 'jazz00079.png', 'jazz00053.png', 'jazz00052.png', 'jazz00071.png', 'jazz00092.png', 'jazz00032.png', 'jazz00028.png', 'jazz00031.png', 'jazz00005.png', 'jazz00014.png', 'jazz00042.png', 'jazz00008.png', 'jazz00075.png', 'jazz00029.png', 'jazz00080.png', 'jazz00065.png', 'jazz00049.png', 'jazz00089.png', 'jazz00070.png', 'jazz00064.png', 'jazz00086.png', 'jazz00038.png', 'jazz00002.png', 'jazz00020.png', 'jazz00093.png', 'jazz00074.png', 'jazz00043.png', 'jazz00067.png', 'jazz00058.png', 'jazz00076.png', 'jazz00045.png', 'jazz00044.png', 'jazz00000.png', 'jazz00095.png', 'jazz00083.png', 'jazz00085.png', 'jazz00041.png', 'jazz00073.png', 'jazz00006.png', 'jazz00035.png', 'jazz00094.png', 'jazz00057.png', 'jazz00081.png', 'jazz00088.png', 'jazz00068.png', 'jazz00013.png', 'jazz00047.png', 'jazz00063.png', 'jazz00066.png', 'jazz00040.png', 'jazz00046.png', 'jazz00056.png', 'jazz00097.png', 'jazz00069.png', 'jazz00082.png', 'jazz00033.png', 'jazz00023.png', 'jazz00016.png', 'jazz00024.png', 'jazz00034.png', 'jazz00015.png', 'jazz00003.png', 'jazz00019.png', 'jazz00011.png', 'jazz00077.png', 'jazz00001.png', 'jazz00090.png', 'jazz00010.png', 'jazz00048.png', 'jazz00030.png', 'jazz00078.png', 'jazz00007.png', 'jazz00012.png', 'jazz00039.png', 'jazz00098.png', 'jazz00059.png', 'jazz00018.png', 'jazz00027.png', 'jazz00050.png', 'jazz00026.png', 'jazz00051.png', 'jazz00036.png', 'jazz00037.png', 'jazz00087.png', 'jazz00017.png', 'jazz00062.png', 'jazz00025.png', 'jazz00004.png', 'jazz00061.png', 'jazz00021.png', 'jazz00055.png', 'jazz00084.png', 'jazz00022.png', 'jazz00099.png', 'jazz00072.png']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/Image files/Jazz - Images'\n",
    "\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "print(img_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4f8392d",
   "metadata": {},
   "source": [
    "The images get converted to black and white, so the pixel values are either 0 (black) or 1 (white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5517afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_images(img_list,path):\n",
    "    pixels = []\n",
    "    imgs = []\n",
    "    for i in range(len(img_list)):\n",
    "        if 'png' in img_list[i]:\n",
    "            try:\n",
    "                img = Image.open(path+'/'+img_list[i],'r')\n",
    "                img = img.convert('1')\n",
    "                img = img.resize((106, 106)) # added by me (turns them into smaller images)\n",
    "                pix = np.array(img.getdata())\n",
    "                pix = pix.astype('float32')\n",
    "                pix /= 255.0\n",
    "                pixels.append(pix.reshape(106, 106, 1))\n",
    "                imgs.append(img)\n",
    "            except:\n",
    "                pass\n",
    "    return np.array(pixels),imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daba8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(pix_list):\n",
    "    array = np.array(pix_list.reshape(106,106), dtype=np.uint8)\n",
    "    new_image = Image.fromarray(array)\n",
    "    new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30d09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels,imgs = access_images(img_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c8a8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 106, 106, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2ce222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAABqAQAAAAB8Wvk6AAABR0lEQVR4nO2UMUoDQRiFvxkHs4QUGwvtZI6QI2xAxGPEG6SwsBCcgGCpN1A8g60wtlY5gUTwACIpNhr2t9js7OzGwsIign/35r3/zZv5mVFCVI+aRv0JaFgkAcimpPqHvwtNEy5b4usKS16rxWu2XKwu2XFgAZhiYyvPqBZnVaPX6NSMhiGW5PR6EQvzOTSt4LgJBVSIUfcqZihKDg3dE0BZ+VZclwrOlguNgEZZYFadeK3XAgmDNdaJb4kN2+f5fPfmBaEPyGLvtsOgjNQWh1Su5awrtiSK1ZrNANePbyMFMMFqQALLaCh55Qf1WDR0D6/wkyrJQicM3SoVkmehS7xGpTiM249Djut9FTAN+yrxxuI+TeoA+bCZx2EOdhBvKF5ndylm+SAaNJxR5EdgKMCg3k/fRlyq++entSkYOvGnu1Gv7IfwC8tXgbPAhINWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=106x106 at 0x7FD34827B550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dfb6b2",
   "metadata": {},
   "source": [
    "# 2. Define discriminator and generator  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3bdf4e7",
   "metadata": {},
   "source": [
    "Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d84c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape = (106,106,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate = 0.0002, beta_1=0.5) # lr was deprecated\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5a54153",
   "metadata": {},
   "source": [
    "Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9a0061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 53 * 53\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((53, 53, 128)))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2DTranspose(1024, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2D(1, (7,7) , padding='same',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10eb1b",
   "metadata": {},
   "source": [
    "# 3. Put them together to define the full GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af994074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c1a5e0",
   "metadata": {},
   "source": [
    "# 4. Define functions to generate fake and real points"
   ]
  },
  {
   "cell_type": "raw",
   "id": "976f6c4f",
   "metadata": {},
   "source": [
    "The latent_points work as the input of the generator while the fake and real samples are to train and test the discriminator.\n",
    "\n",
    "The following are: \n",
    "\n",
    "- Generate real samples: selects a datapoint from array\n",
    "\n",
    "- Generate latent points: generatres a random array of a give size (to be inputed into generator)\n",
    "\n",
    "- Generate fake samples: takes random data and generates a picture w/ generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840396da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433392c",
   "metadata": {},
   "source": [
    "# 5. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8936055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 is way too many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01062293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=10):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "#         if (i+1) % 10 == 0:\n",
    "#             print(\"Iteration: \", i)\n",
    "#             summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f417fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 106, 106, 1)\n",
      ">1, 1/9, d=0.499, g=0.769\n",
      ">1, 2/9, d=0.454, g=0.776\n",
      ">1, 3/9, d=0.158, g=0.814\n",
      ">1, 4/9, d=0.032, g=0.794\n",
      ">1, 5/9, d=0.051, g=0.754\n",
      ">1, 6/9, d=0.132, g=0.717\n",
      ">1, 7/9, d=0.103, g=0.654\n",
      ">1, 8/9, d=0.105, g=0.630\n",
      ">1, 9/9, d=0.079, g=0.606\n",
      ">2, 1/9, d=0.023, g=0.595\n",
      ">2, 2/9, d=0.015, g=0.592\n",
      ">2, 3/9, d=0.020, g=0.582\n",
      ">2, 4/9, d=0.023, g=0.561\n",
      ">2, 5/9, d=0.011, g=0.523\n",
      ">2, 6/9, d=0.007, g=0.515\n",
      ">2, 7/9, d=0.038, g=0.529\n",
      ">2, 8/9, d=0.019, g=0.550\n",
      ">2, 9/9, d=0.014, g=0.620\n",
      ">3, 1/9, d=0.013, g=0.526\n",
      ">3, 2/9, d=0.186, g=0.508\n",
      ">3, 3/9, d=0.182, g=0.423\n",
      ">3, 4/9, d=0.313, g=0.602\n",
      ">3, 5/9, d=0.089, g=0.492\n",
      ">3, 6/9, d=0.244, g=0.346\n",
      ">3, 7/9, d=0.271, g=0.349\n",
      ">3, 8/9, d=0.116, g=0.520\n",
      ">3, 9/9, d=0.025, g=0.390\n",
      ">4, 1/9, d=0.191, g=0.561\n",
      ">4, 2/9, d=0.137, g=0.679\n",
      ">4, 3/9, d=0.082, g=0.456\n",
      ">4, 4/9, d=0.335, g=0.756\n",
      ">4, 5/9, d=0.231, g=0.575\n",
      ">4, 6/9, d=0.044, g=0.472\n",
      ">4, 7/9, d=0.122, g=0.515\n",
      ">4, 8/9, d=0.218, g=0.332\n",
      ">4, 9/9, d=0.033, g=0.448\n",
      ">5, 1/9, d=0.131, g=0.579\n",
      ">5, 2/9, d=0.182, g=0.562\n",
      ">5, 3/9, d=0.186, g=0.441\n",
      ">5, 4/9, d=0.154, g=0.615\n",
      ">5, 5/9, d=0.111, g=0.474\n",
      ">5, 6/9, d=0.115, g=0.513\n",
      ">5, 7/9, d=0.068, g=0.610\n",
      ">5, 8/9, d=0.057, g=0.524\n",
      ">5, 9/9, d=0.182, g=0.547\n",
      ">6, 1/9, d=0.045, g=0.550\n",
      ">6, 2/9, d=0.105, g=0.493\n",
      ">6, 3/9, d=0.122, g=0.397\n",
      ">6, 4/9, d=0.059, g=0.383\n",
      ">6, 5/9, d=0.015, g=0.542\n",
      ">6, 6/9, d=0.065, g=0.559\n",
      ">6, 7/9, d=0.025, g=0.493\n",
      ">6, 8/9, d=0.065, g=0.385\n",
      ">6, 9/9, d=0.083, g=0.404\n",
      ">7, 1/9, d=0.046, g=0.486\n",
      ">7, 2/9, d=0.033, g=0.424\n",
      ">7, 3/9, d=0.066, g=0.454\n",
      ">7, 4/9, d=0.081, g=0.441\n",
      ">7, 5/9, d=0.036, g=0.381\n",
      ">7, 6/9, d=0.064, g=0.420\n",
      ">7, 7/9, d=0.028, g=0.351\n",
      ">7, 8/9, d=0.041, g=0.363\n",
      ">7, 9/9, d=0.044, g=0.362\n",
      ">8, 1/9, d=0.077, g=0.401\n",
      ">8, 2/9, d=0.042, g=0.353\n",
      ">8, 3/9, d=0.057, g=0.374\n",
      ">8, 4/9, d=0.035, g=0.381\n",
      ">8, 5/9, d=0.052, g=0.331\n",
      ">8, 6/9, d=0.039, g=0.360\n",
      ">8, 7/9, d=0.038, g=0.339\n",
      ">8, 8/9, d=0.027, g=0.353\n",
      ">8, 9/9, d=0.021, g=0.353\n",
      ">9, 1/9, d=0.051, g=0.331\n",
      ">9, 2/9, d=0.022, g=0.321\n",
      ">9, 3/9, d=0.082, g=0.379\n",
      ">9, 4/9, d=0.102, g=0.305\n",
      ">9, 5/9, d=0.054, g=0.359\n",
      ">9, 6/9, d=0.063, g=0.325\n",
      ">9, 7/9, d=0.120, g=0.341\n",
      ">9, 8/9, d=0.080, g=0.301\n",
      ">9, 9/9, d=0.035, g=0.317\n",
      ">10, 1/9, d=0.008, g=0.312\n",
      ">10, 2/9, d=0.088, g=0.276\n",
      ">10, 3/9, d=0.015, g=0.289\n",
      ">10, 4/9, d=0.066, g=0.306\n",
      ">10, 5/9, d=0.025, g=0.274\n",
      ">10, 6/9, d=0.046, g=0.301\n",
      ">10, 7/9, d=0.029, g=0.269\n",
      ">10, 8/9, d=0.057, g=0.259\n",
      ">10, 9/9, d=0.030, g=0.273\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(pixels.shape)\n",
    "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb84d7b",
   "metadata": {},
   "source": [
    "# 6. Use newly trained generator to generate new song images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bc5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f3813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6eaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 0\n",
    "\n",
    "while number_images < 10: \n",
    "    latent_points = generate_latent_points(latent_dim,1)\n",
    "    X = g_model.predict(latent_points)\n",
    "    # A one in the discriminator means it thinks it is real\n",
    "    prediction = np.round(d_model.predict(X)[0][0])\n",
    "    \n",
    "    if prediction == 1: \n",
    "        arr = np.array(X.reshape(106,106),dtype = np.uint8);\n",
    "        arr*= 255;\n",
    "        new_image = Image.fromarray(arr,'L')\n",
    "        plt.figure(); \n",
    "        plt.imshow(new_image);\n",
    "        new_image.save('04_16_attempt_1_jazz_music_15_epochs_OutputNumber_' + str(number_images) + '.png')\n",
    "        number_images += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1dd9e",
   "metadata": {},
   "source": [
    "# 7. Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee55a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('04-16-jazz-music-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1fd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('04-16-jazz-music-generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a233df",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-16-jazz-music-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-16-jazz-music-discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-16-jazz-music-full-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5feb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-16-jazz-music-full-gan.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecf1a7",
   "metadata": {},
   "source": [
    "# 8. Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f521ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca176ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = 0; \n",
    "image2midi('04_16_attempt_1_jazz_music_10_epochs_OutputNumber_' + str(ex) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154ddb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
