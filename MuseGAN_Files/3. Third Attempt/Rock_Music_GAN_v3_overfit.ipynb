{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733fff07",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b931e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "     |████████████████████████████████| 458.3 MB 12 kB/s               \n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 57.1 MB/s            \n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 93.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 289 kB/s             \n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 41.6 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 70.9 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.44.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "     |████████████████████████████████| 4.3 MB 112.7 MB/s            \n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     |████████████████████████████████| 65 kB 6.9 MB/s              \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 64.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 58.4 MB/s            \n",
      "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 99.4 MB/s            \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 11.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 97.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     |████████████████████████████████| 151 kB 102.0 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=8881960af788f89b124fd3a1c7c50c179a080e66d67f715b34076a18f51800ba\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=ef0e5b862b8b0d90bb8af20a7c263931b0f9169c5a29a78c19ec4f3f15cfe94d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: typing-extensions, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.0\n",
      "    Uninstalling importlib-metadata-3.7.0:\n",
      "      Successfully uninstalled importlib-metadata-3.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.12.2 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "astroid 2.9.0 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.24.42 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.44.0 importlib-metadata-4.8.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3\n",
      "Collecting music21\n",
      "  Downloading music21-6.7.1.tar.gz (19.2 MB)\n",
      "     |████████████████████████████████| 19.2 MB 24.0 MB/s eta 0:00:01     |████████████████████████████████| 19.2 MB 24.0 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: chardet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (3.0.4)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (1.0.1)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (8.7.0)\n",
      "Collecting webcolors\n",
      "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
      "Building wheels for collected packages: music21\n",
      "  Building wheel for music21 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for music21: filename=music21-6.7.1-py3-none-any.whl size=21941692 sha256=9c8af9b3e95556485e31b2ccb33f956c150cf1cf1578c5117639d1d3042a5540\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/66/b8/68/c374fb21ae1e0faea5b8bc7e537b8e89e91da904edc5c3e224\n",
      "Successfully built music21\n",
      "Installing collected packages: webcolors, music21\n",
      "Successfully installed music21-6.7.1 webcolors-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow \n",
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cd23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from music21 import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551343e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import sys\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "\n",
    "def extractNote(element):\n",
    "    return int(element.pitch.ps)\n",
    "\n",
    "def extractDuration(element):\n",
    "    return element.duration.quarterLength\n",
    "\n",
    "def get_notes(notes_to_parse):\n",
    "\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    durations = []\n",
    "    notes = []\n",
    "    start = []\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "\n",
    "            start.append(element.offset)\n",
    "            notes.append(extractNote(element))\n",
    "            durations.append(extractDuration(element))\n",
    "                \n",
    "        elif isinstance(element, chord.Chord):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "            for chord_note in element.notes:\n",
    "                start.append(element.offset)\n",
    "                durations.append(extractDuration(element))\n",
    "                notes.append(extractNote(chord_note))\n",
    "\n",
    "    return {\"start\":start, \"pitch\":notes, \"dur\":durations}\n",
    "\n",
    "\n",
    "def midi2image(midi_path, max_repetitions = float(\"inf\"), resolution = 0.25, lowerBoundNote = 21, upperBoundNote = 127, maxSongLength = 100):\n",
    "    mid = converter.parse(midi_path)\n",
    "\n",
    "    instruments = instrument.partitionByInstrument(mid)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    try:\n",
    "        i=0\n",
    "        for instrument_i in instruments.parts:\n",
    "            notes_to_parse = instrument_i.recurse()\n",
    "\n",
    "            notes_data = get_notes(notes_to_parse)\n",
    "            if len(notes_data[\"start\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            if instrument_i.partName is None:\n",
    "                data[\"instrument_{}\".format(i)] = notes_data\n",
    "                i+=1\n",
    "            else:\n",
    "                data[instrument_i.partName] = notes_data\n",
    "\n",
    "    except:\n",
    "        notes_to_parse = mid.flat.notes\n",
    "        data[\"instrument_0\"] = get_notes(notes_to_parse)\n",
    "\n",
    "    for instrument_name, values in data.items():\n",
    "        # https://en.wikipedia.org/wiki/Scientific_pitch_notation#Similar_systems\n",
    "\n",
    "        pitches = values[\"pitch\"]\n",
    "        durs = values[\"dur\"]\n",
    "        starts = values[\"start\"]\n",
    "\n",
    "        index = 0\n",
    "        while index < max_repetitions:\n",
    "            matrix = np.zeros((upperBoundNote-lowerBoundNote,maxSongLength))\n",
    "\n",
    "\n",
    "            for dur, start, pitch in zip(durs, starts, pitches):\n",
    "                dur = int(dur/resolution)\n",
    "                start = int(start/resolution)\n",
    "\n",
    "                if not start > index*(maxSongLength+1) or not dur+start < index*maxSongLength:\n",
    "                    for j in range(start,start+dur):\n",
    "                        if j - index*maxSongLength >= 0 and j - index*maxSongLength < maxSongLength:\n",
    "                            matrix[pitch-lowerBoundNote,j - index*maxSongLength] = 255\n",
    "\n",
    "            if matrix.any(): # If matrix contains no notes (only zeros) don't save it\n",
    "                imwrite(midi_path.split(\"/\")[-1].replace(\".mid\",f\"_{instrument_name}_{index}.png\"),matrix.astype(np.uint8))\n",
    "                index += 1\n",
    "            else:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4913b",
   "metadata": {},
   "source": [
    "# 1. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67db6779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0149193d",
   "metadata": {},
   "source": [
    "We will begin by creating the dataset for the classical music image files \n",
    "\n",
    "In future iterations, we may want to consider analyzing colored images to extract more infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef0c1e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnyConv.com__rock.00035.mid', 'AnyConv.com__rock.00015.mid', 'AnyConv.com__rock.00010.mid', 'AnyConv.com__rock.00049.mid', 'AnyConv.com__rock.00006.mid', 'AnyConv.com__rock.00040.mid', 'AnyConv.com__rock.00025.mid', 'AnyConv.com__rock.00019.mid', 'AnyConv.com__rock.00043.mid', 'AnyConv.com__rock.00009.mid', 'AnyConv.com__rock.00047.mid', 'AnyConv.com__rock.00042.mid', 'AnyConv.com__rock.00005.mid', 'AnyConv.com__rock.00033.mid', 'AnyConv.com__rock.00001.mid', 'AnyConv.com__rock.00031.mid', 'AnyConv.com__rock.00030.mid', 'AnyConv.com__rock.00013.mid', 'AnyConv.com__rock.00038.mid', 'AnyConv.com__rock.00021.mid', 'AnyConv.com__rock.00037.mid', 'AnyConv.com__rock.00058.mid', 'AnyConv.com__rock.00053.mid', 'AnyConv.com__rock.00007.mid', 'AnyConv.com__rock.00027.mid', 'AnyConv.com__rock.00059.mid', 'AnyConv.com__rock.00018.mid', 'AnyConv.com__rock.00060.mid', 'AnyConv.com__rock.00016.mid', 'AnyConv.com__rock.00039.mid', 'AnyConv.com__rock.00044.mid', 'AnyConv.com__rock.00011.mid', 'AnyConv.com__rock.00054.mid', 'AnyConv.com__rock.00022.mid', 'AnyConv.com__rock.00004.mid', 'AnyConv.com__rock.00029.mid', 'AnyConv.com__rock.00003.mid', 'AnyConv.com__rock.00024.mid', 'AnyConv.com__rock.00028.mid', 'AnyConv.com__rock.00032.mid', 'AnyConv.com__rock.00012.mid', 'AnyConv.com__rock.00050.mid', 'AnyConv.com__rock.00014.mid', 'AnyConv.com__rock.00034.mid', 'AnyConv.com__rock.00055.mid', 'AnyConv.com__rock.00017.mid', 'AnyConv.com__rock.00041.mid', 'AnyConv.com__rock.00056.mid', 'AnyConv.com__rock.00046.mid', 'AnyConv.com__rock.00052.mid', 'AnyConv.com__rock.00036.mid', 'AnyConv.com__rock.00000.mid', 'AnyConv.com__rock.00045.mid', 'AnyConv.com__rock.00008.mid']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/Midi Files/Rock'\n",
    "\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "print(img_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3ee78b7",
   "metadata": {},
   "source": [
    "Change file names --> They need to end in .mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65159304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for im in img_list: \n",
    "#     path = os.getcwd() + '/Midi Files/Classical/'\n",
    "#     os.rename(path + im, path + im[:-1]) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a3c44fa",
   "metadata": {},
   "source": [
    "Convert midi songs to png - TO KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4de1d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixels = []\n",
    "# imgs = []\n",
    "# for i in img_list:\n",
    "#     print(i)\n",
    "#     try:\n",
    "#         midi2image(os.getcwd() + '/Midi Files/Classical/' + i)\n",
    "#         for j in range(3):\n",
    "#             try: \n",
    "#                 im = Image.open(os.getcwd() + '/' + i[:-4] + '_Piano_' + str(j) + '.png')\n",
    "#                 im = im.resize((106, 106))\n",
    "#                 im.save(os.getcwd() + '/' + i[:-4] + '_Piano_' + str(j) + '.png')\n",
    "#             except: \n",
    "#                 pass\n",
    "#     except: \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab216da5",
   "metadata": {},
   "source": [
    "Now, do process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57049696",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/Rock-Images'\n",
    "\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "# print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cc453b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_images(img_list,path):\n",
    "    pixels = []\n",
    "    imgs = []\n",
    "    for i in range(len(img_list)):\n",
    "        if 'png' in img_list[i]:\n",
    "            try:\n",
    "                img = Image.open(path+'/'+img_list[i],'r')\n",
    "                img = img.convert('1')\n",
    "                img = img.resize((106, 106)) # added by me (turns them into smaller images)\n",
    "                pix = np.array(img.getdata())\n",
    "                pix = pix.astype('float32')\n",
    "                pix /= 255.0\n",
    "                pixels.append(pix.reshape(106, 106, 1))\n",
    "                imgs.append(img)\n",
    "            except:\n",
    "                pass\n",
    "    return np.array(pixels),imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e087236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(pix_list):\n",
    "    array = np.array(pix_list.reshape(106,106), dtype=np.uint8)\n",
    "    new_image = Image.fromarray(array)\n",
    "    new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49acea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels,imgs = access_images(img_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d44e9bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 106, 106, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "636a82dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAABqAQAAAAB8Wvk6AAAC7ElEQVR4nO2ST2hcVRSHv3PnzuTFDMlNjXaMojdpqNFFeehCIZi+2opDERSxu1KmEoq7RlCkIslpqJqFSJSiIIJTdBn8t0gRbPsSxZ1iEbEgxSRKOmCZRpvSGTN5z8WbtFToUtx4dueec358v3sO/Kdh/pEHN2/1N2RdJx26Oe8w7pqU+ANzLXeu5hdNosS89pYg5aKClXndbHviptIRzDggQgUgyOcub8jhwocXMjo7DHgbXxs4BjEBxsx7dUR5JaIBQOgIrmvvuufiDGDzsvlSzDzHsDqiQPeTdc0qlTZJRmsBqoPVGyCJ2n6xLSTNEjeOgZ31UyvdHVPpJz9llE4BXBRAYf0RIBh2EJQw610/HhSO3P0nLlhTaqhSHT77DFiBgjB6V3x9RzG4Cm1EM3tEdj9/ZjlJc1cun4/pVRHmjIDYByBnBif2E8RAIHBn3ohU4t3Qyxjkf56LCPuL4JyBb31hfDJ9c+RCzMNAYOEogYJ1wI5cev7B3/RihVKfgU6lEoCCyDSseEKzM01P517Z2lQ6Fx6F4SkczgGHciriyh6sNeBev7R2W6MIYItQBmCmvSPzxUMn0+TE6krbrqhFmuUiOPcc6Hpi4Zbp9r0426GNsBgCTpSBGFAis2UMyD5JqtiO8d4As3FMfv0jrQStZt+lhtKzLCuzJfCY48DL756exHe3lVhKT8Wbly3wqfLSDDraprTkRYgBB/B4vScGG/msPAEbJfbWPBgD6aIRvSNNfIADZo3o1UXUOwB+GNv6Vc2X/bM4AqgpclTho0xq9VBBCfcydOs4Blr28ORGspxgtu8JIY2J+PyvL72zvdNwRilxe/Cdz471PiPx4hZCcBjMq40XVqudO1rkhvZMQJp0pd8060ll4Pi+ESwn1li69+mnSvL275+NWmHpg7MLzRdb2w58Pw/1q1cS+u9/g21Dtl9J0oNpEn78PgPv7FuAVs97hV3bu0IG+x6bAmzll69DlBL/x78XfwNhj+Ucti79zwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=106x106 at 0x7FCBE1F4C9E8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58d2e287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels[0][50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b615e",
   "metadata": {},
   "source": [
    "# 2. Define discriminator and generator  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "381d9f82",
   "metadata": {},
   "source": [
    "Discriminator\n",
    "\n",
    "Possible idea. Since dataset is small, can we remove dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4248ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape = (106,106,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate = 0.0002, beta_1=0.5) # lr was deprecated\n",
    "#     opt = Adam(learning_rate = 0.001, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6d128c7",
   "metadata": {},
   "source": [
    "Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b63e5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 53 * 53\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((53, 53, 128)))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2DTranspose(1024, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2D(1, (7,7) , padding='same',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e6983",
   "metadata": {},
   "source": [
    "# 3. Put them together to define the full GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e20cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "#     opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5264d9",
   "metadata": {},
   "source": [
    "# 4. Define functions to generate fake and real points"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8e3e837",
   "metadata": {},
   "source": [
    "The latent_points work as the input of the generator while the fake and real samples are to train and test the discriminator.\n",
    "\n",
    "The following are: \n",
    "\n",
    "- Generate real samples: selects a datapoint from array\n",
    "\n",
    "- Generate latent points: generatres a random array of a give size (to be inputed into generator)\n",
    "\n",
    "- Generate fake samples: takes random data and generates a picture w/ generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6376e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7b8e8",
   "metadata": {},
   "source": [
    "# 5. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ec6599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 is way too many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742a6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=17):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "#         if (i+1) % 10 == 0:\n",
    "#             print(\"Iteration: \", i)\n",
    "#             summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e2615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 106, 106, 1)\n",
      ">1, 1/9, d=0.710, g=0.861\n",
      ">1, 2/9, d=0.340, g=0.865\n",
      ">1, 3/9, d=1.134, g=0.671\n",
      ">1, 4/9, d=1.087, g=0.694\n",
      ">1, 5/9, d=0.656, g=0.709\n",
      ">1, 6/9, d=0.319, g=0.701\n",
      ">1, 7/9, d=0.209, g=0.680\n",
      ">1, 8/9, d=0.183, g=0.651\n",
      ">1, 9/9, d=0.189, g=0.619\n",
      ">2, 1/9, d=0.089, g=0.598\n",
      ">2, 2/9, d=0.154, g=0.571\n",
      ">2, 3/9, d=0.095, g=0.560\n",
      ">2, 4/9, d=0.164, g=0.526\n",
      ">2, 5/9, d=0.240, g=0.505\n",
      ">2, 6/9, d=0.252, g=0.490\n",
      ">2, 7/9, d=0.982, g=0.457\n",
      ">2, 8/9, d=0.656, g=0.545\n",
      ">2, 9/9, d=0.358, g=0.653\n",
      ">3, 1/9, d=0.229, g=0.662\n",
      ">3, 2/9, d=0.189, g=0.751\n",
      ">3, 3/9, d=0.138, g=0.778\n",
      ">3, 4/9, d=0.259, g=0.788\n",
      ">3, 5/9, d=0.241, g=0.769\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(pixels.shape)\n",
    "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2913f0ab",
   "metadata": {},
   "source": [
    "# 6. Use newly trained generator to generate new song images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be8459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cd47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 0\n",
    "\n",
    "while number_images < 10: \n",
    "    latent_points = generate_latent_points(latent_dim,1)\n",
    "    X = g_model.predict(latent_points)\n",
    "    # A one in the discriminator means it thinks it is real\n",
    "    prediction = np.round(d_model.predict(X)[0][0])\n",
    "    \n",
    "    if prediction == 1: \n",
    "        arr = np.array(X.reshape(106,106),dtype = np.uint8);\n",
    "        arr*= 255;\n",
    "        new_image = Image.fromarray(arr,'L')\n",
    "        plt.figure(); \n",
    "        plt.imshow(new_image);\n",
    "        new_image.save('04_21_attempt_3_rock_overfit_OutputNumber_' + str(number_images) + '.png')\n",
    "        number_images += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8da0c",
   "metadata": {},
   "source": [
    "# 7. Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c464cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('04-21-rock-music-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a0f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('04-21-rock-music-generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-21-rock-music-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-21-rock-music-discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b83175",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-21-rock-music-full-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8508be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-21-rock-music-full-gan.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6864abb9",
   "metadata": {},
   "source": [
    "# 8. Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15c3ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7fdf841",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image2midi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9a85fc028daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'04_16_attempt_1_classical_music_10_epochs_OutputNumber_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image2midi' is not defined"
     ]
    }
   ],
   "source": [
    "# ex = 0; \n",
    "# image2midi('04_16_attempt_1_classical_music_10_epochs_OutputNumber_' + str(ex) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
