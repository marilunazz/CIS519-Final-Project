{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae974e05",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e751db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.2)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: music21 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (6.7.1)\n",
      "Requirement already satisfied: chardet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (3.0.4)\n",
      "Requirement already satisfied: webcolors in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (1.11.1)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (1.0.1)\n",
      "Requirement already satisfied: more-itertools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from music21) (8.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow \n",
    "!pip install music21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16301f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy import vstack\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten,BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from music21 import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "822ff349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import converter, instrument, note, chord\n",
    "import sys\n",
    "import numpy as np\n",
    "from imageio import imwrite\n",
    "\n",
    "def extractNote(element):\n",
    "    return int(element.pitch.ps)\n",
    "\n",
    "def extractDuration(element):\n",
    "    return element.duration.quarterLength\n",
    "\n",
    "def get_notes(notes_to_parse):\n",
    "\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    durations = []\n",
    "    notes = []\n",
    "    start = []\n",
    "\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "\n",
    "            start.append(element.offset)\n",
    "            notes.append(extractNote(element))\n",
    "            durations.append(extractDuration(element))\n",
    "                \n",
    "        elif isinstance(element, chord.Chord):\n",
    "            if element.isRest:\n",
    "                continue\n",
    "            for chord_note in element.notes:\n",
    "                start.append(element.offset)\n",
    "                durations.append(extractDuration(element))\n",
    "                notes.append(extractNote(chord_note))\n",
    "\n",
    "    return {\"start\":start, \"pitch\":notes, \"dur\":durations}\n",
    "\n",
    "\n",
    "def midi2image(midi_path, max_repetitions = float(\"inf\"), resolution = 0.25, lowerBoundNote = 21, upperBoundNote = 127, maxSongLength = 100):\n",
    "    mid = converter.parse(midi_path)\n",
    "\n",
    "    instruments = instrument.partitionByInstrument(mid)\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    try:\n",
    "        i=0\n",
    "        for instrument_i in instruments.parts:\n",
    "            notes_to_parse = instrument_i.recurse()\n",
    "\n",
    "            notes_data = get_notes(notes_to_parse)\n",
    "            if len(notes_data[\"start\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            if instrument_i.partName is None:\n",
    "                data[\"instrument_{}\".format(i)] = notes_data\n",
    "                i+=1\n",
    "            else:\n",
    "                data[instrument_i.partName] = notes_data\n",
    "\n",
    "    except:\n",
    "        notes_to_parse = mid.flat.notes\n",
    "        data[\"instrument_0\"] = get_notes(notes_to_parse)\n",
    "\n",
    "    for instrument_name, values in data.items():\n",
    "        # https://en.wikipedia.org/wiki/Scientific_pitch_notation#Similar_systems\n",
    "\n",
    "        pitches = values[\"pitch\"]\n",
    "        durs = values[\"dur\"]\n",
    "        starts = values[\"start\"]\n",
    "\n",
    "        index = 0\n",
    "        while index < max_repetitions:\n",
    "            matrix = np.zeros((upperBoundNote-lowerBoundNote,maxSongLength))\n",
    "\n",
    "\n",
    "            for dur, start, pitch in zip(durs, starts, pitches):\n",
    "                dur = int(dur/resolution)\n",
    "                start = int(start/resolution)\n",
    "\n",
    "                if not start > index*(maxSongLength+1) or not dur+start < index*maxSongLength:\n",
    "                    for j in range(start,start+dur):\n",
    "                        if j - index*maxSongLength >= 0 and j - index*maxSongLength < maxSongLength:\n",
    "                            matrix[pitch-lowerBoundNote,j - index*maxSongLength] = 255\n",
    "\n",
    "            if matrix.any(): # If matrix contains no notes (only zeros) don't save it\n",
    "                imwrite(midi_path.split(\"/\")[-1].replace(\".mid\",f\"_{instrument_name}_{index}.png\"),matrix.astype(np.uint8))\n",
    "                index += 1\n",
    "            else:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1c71a",
   "metadata": {},
   "source": [
    "# 1. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84db2f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ca0c6ad",
   "metadata": {},
   "source": [
    "We will begin by creating the dataset for the classical music image files \n",
    "\n",
    "In future iterations, we may want to consider analyzing colored images to extract more infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa09afa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AnyConv.com__classical.00022.mid', 'AnyConv.com__classical.00045.mid', 'AnyConv.com__classical.00035.mid', 'AnyConv.com__classical.00047.mid', 'AnyConv.com__classical.00049.mid', 'AnyConv.com__classical.00023.mid', 'AnyConv.com__classical.00014.mid', 'AnyConv.com__classical.00097.mid', 'AnyConv.com__classical.00043.mid', 'AnyConv.com__classical.00095.mid', 'AnyConv.com__classical.00046.mid', 'AnyConv.com__classical.00099.mid', 'AnyConv.com__classical.00008.mid', 'AnyConv.com__classical.00019.mid', 'AnyConv.com__classical.00020.mid', 'AnyConv.com__classical.00092.mid', 'AnyConv.com__classical.00018.mid', 'AnyConv.com__classical.00032.mid', 'AnyConv.com__classical.00064.mid', 'AnyConv.com__classical.00030.mid', 'AnyConv.com__classical.00057.mid', 'AnyConv.com__classical.00026.mid', 'AnyConv.com__classical.00017.mid', 'AnyConv.com__classical.00033.mid', 'AnyConv.com__classical.00029.mid', 'AnyConv.com__classical.00021.mid', 'AnyConv.com__classical.00050.mid', 'AnyConv.com__classical.00025.mid', 'AnyConv.com__classical.00086.mid', '.ipynb_checkpoint', 'AnyConv.com__classical.00059.mid', 'AnyConv.com__classical.00000.mid', 'AnyConv.com__classical.00036.mid', 'AnyConv.com__classical.00001.mid', 'AnyConv.com__classical.00005.mid', 'AnyConv.com__classical.00041.mid', 'AnyConv.com__classical.00009.mid', 'AnyConv.com__classical.00093.mid', 'AnyConv.com__classical.00055.mid', 'AnyConv.com__classical.00056.mid', 'AnyConv.com__classical.00094.mid', 'AnyConv.com__classical.00015.mid', 'AnyConv.com__classical.00010.mid', 'AnyConv.com__classical.00027.mid', 'AnyConv.com__classical.00013.mid', 'AnyConv.com__classical.00024.mid', 'AnyConv.com__classical.00060.mid', 'AnyConv.com__classical.00089.mid', 'AnyConv.com__classical.00063.mid', 'AnyConv.com__classical.00011.mid', 'AnyConv.com__classical.00085.mid', 'AnyConv.com__classical.00065.mid', 'AnyConv.com__classical.00007.mid', 'AnyConv.com__classical.00090.mid', 'AnyConv.com__classical.00087.mid', 'AnyConv.com__classical.00054.mid', 'AnyConv.com__classical.00028.mid', 'AnyConv.com__classical.00096.mid', 'AnyConv.com__classical.00091.mid', 'AnyConv.com__classical.00037.mid', 'AnyConv.com__classical.00034.mid', 'AnyConv.com__classical.00061.mid', 'AnyConv.com__classical.00058.mid', 'AnyConv.com__classical.00031.mid', 'AnyConv.com__classical.00088.mid', 'AnyConv.com__classical.00038.mid', 'AnyConv.com__classical.00039.mid', 'AnyConv.com__classical.00052.mid', 'AnyConv.com__classical.00053.mid', 'AnyConv.com__classical.00062.mid', 'AnyConv.com__classical.00040.mid', 'AnyConv.com__classical.00048.mid', 'AnyConv.com__classical.00044.mid', 'AnyConv.com__classical.00042.mid', 'AnyConv.com__classical.00012.mid']\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/Midi Files/Classical'\n",
    "\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "print(img_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ab625b2",
   "metadata": {},
   "source": [
    "Change file names --> They need to end in .mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ca68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for im in img_list: \n",
    "#     path = os.getcwd() + '/Midi Files/Classical/'\n",
    "#     os.rename(path + im, path + im[:-1]) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcc26127",
   "metadata": {},
   "source": [
    "Convert midi songs to png - TO KEEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0fd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixels = []\n",
    "# imgs = []\n",
    "# for i in img_list:\n",
    "#     print(i)\n",
    "#     try:\n",
    "#         midi2image(os.getcwd() + '/Midi Files/Classical/' + i)\n",
    "#         for j in range(3):\n",
    "#             try: \n",
    "#                 im = Image.open(os.getcwd() + '/' + i[:-4] + '_Piano_' + str(j) + '.png')\n",
    "#                 im = im.resize((106, 106))\n",
    "#                 im.save(os.getcwd() + '/' + i[:-4] + '_Piano_' + str(j) + '.png')\n",
    "#             except: \n",
    "#                 pass\n",
    "#     except: \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48e00295",
   "metadata": {},
   "source": [
    "Now, do process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "043e078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/Classical-Images'\n",
    "\n",
    "img_list = os.listdir(path)\n",
    "\n",
    "# print(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4864ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_images(img_list,path):\n",
    "    pixels = []\n",
    "    imgs = []\n",
    "    for i in range(len(img_list)):\n",
    "        if 'png' in img_list[i]:\n",
    "            try:\n",
    "                img = Image.open(path+'/'+img_list[i],'r')\n",
    "                img = img.convert('1')\n",
    "                img = img.resize((106, 106)) # added by me (turns them into smaller images)\n",
    "                pix = np.array(img.getdata())\n",
    "                pix = pix.astype('float32')\n",
    "                pix /= 255.0\n",
    "                pixels.append(pix.reshape(106, 106, 1))\n",
    "                imgs.append(img)\n",
    "            except:\n",
    "                pass\n",
    "    return np.array(pixels),imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "178d7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(pix_list):\n",
    "    array = np.array(pix_list.reshape(106,106), dtype=np.uint8)\n",
    "    new_image = Image.fromarray(array)\n",
    "    new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd461a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels,imgs = access_images(img_list,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1ad747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 106, 106, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09282e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGoAAABqAQAAAAB8Wvk6AAAAb0lEQVR4nGNgGAXkAgVU7h962Vt+AJ8sXkk8gIeBgSEApyzjBzKNhQIHUhRzwFlKWGR/EGUGMwMDAwuG6AEGBmi8MR9gYGBogFvIgaGUgeEDURYxMDAwEqsQBzgAZ/EQq0WAQispBgcG2gGjYOAAAHOlCooetP/pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=1 size=106x106 at 0x7EFDD2691BE0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a12405f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixels[0][50:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251fdfc",
   "metadata": {},
   "source": [
    "# 2. Define discriminator and generator  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "57cc32b8",
   "metadata": {},
   "source": [
    "Discriminator\n",
    "\n",
    "Possible idea. Since dataset is small, can we remove dropout?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2664147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(in_shape = (106,106,1)):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opt = Adam(learning_rate = 0.0002, beta_1=0.5) # lr was deprecated\n",
    "#     opt = Adam(learning_rate = 0.001, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72d70c92",
   "metadata": {},
   "source": [
    "Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61b370fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    n_nodes = 128 * 53 * 53\n",
    "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((53, 53, 128)))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2DTranspose(1024, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(Conv2D(1, (7,7) , padding='same',activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ae3a1e",
   "metadata": {},
   "source": [
    "# 3. Put them together to define the full GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb53428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "    d_model.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(g_model)\n",
    "    model.add(d_model)\n",
    "#     opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    opt = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc976b0",
   "metadata": {},
   "source": [
    "# 4. Define functions to generate fake and real points"
   ]
  },
  {
   "cell_type": "raw",
   "id": "031a18d6",
   "metadata": {},
   "source": [
    "The latent_points work as the input of the generator while the fake and real samples are to train and test the discriminator.\n",
    "\n",
    "The following are: \n",
    "\n",
    "- Generate real samples: selects a datapoint from array\n",
    "\n",
    "- Generate latent points: generatres a random array of a give size (to be inputed into generator)\n",
    "\n",
    "- Generate fake samples: takes random data and generates a picture w/ generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18147d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    X = dataset[ix]\n",
    "    y = ones((n_samples, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    " \n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "\n",
    "\n",
    "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    X = g_model.predict(x_input)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6538f0db",
   "metadata": {},
   "source": [
    "# 5. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b50fde23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 is way too many epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "357b9820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=9, n_batch=22):\n",
    "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for i in range(n_epochs):\n",
    "        for j in range(bat_per_epo):\n",
    "            X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            X, y = vstack((X_real, X_fake)), vstack((y_real, y_fake))\n",
    "            d_loss, _ = d_model.train_on_batch(X, y)\n",
    "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "#         if (i+1) % 10 == 0:\n",
    "#             print(\"Iteration: \", i)\n",
    "#             summarize_performance(i, g_model, d_model, dataset, latent_dim)\n",
    "#             clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe046c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(219, 106, 106, 1)\n",
      ">1, 1/9, d=0.650, g=0.845\n",
      ">1, 2/9, d=0.071, g=0.866\n",
      ">1, 3/9, d=0.847, g=0.676\n",
      ">1, 4/9, d=0.957, g=0.696\n",
      ">1, 5/9, d=0.798, g=0.716\n",
      ">1, 6/9, d=0.661, g=0.714\n",
      ">1, 7/9, d=0.542, g=0.701\n",
      ">1, 8/9, d=0.455, g=0.674\n",
      ">1, 9/9, d=0.343, g=0.643\n",
      ">2, 1/9, d=0.386, g=0.608\n",
      ">2, 2/9, d=0.389, g=0.572\n",
      ">2, 3/9, d=0.404, g=0.561\n",
      ">2, 4/9, d=0.360, g=0.549\n",
      ">2, 5/9, d=0.419, g=0.537\n",
      ">2, 6/9, d=0.365, g=0.519\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "d_model = define_discriminator()\n",
    "g_model = define_generator(latent_dim)\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "print(pixels.shape)\n",
    "train(g_model, d_model, gan_model, np.array(pixels), latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b03bf",
   "metadata": {},
   "source": [
    "# 6. Use newly trained generator to generate new song images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80440ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d600d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    x_input = x_input.reshape(n_samples, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c776e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 0\n",
    "\n",
    "while number_images < 10: \n",
    "    latent_points = generate_latent_points(latent_dim,1)\n",
    "    X = g_model.predict(latent_points)\n",
    "    # A one in the discriminator means it thinks it is real\n",
    "    prediction = np.round(d_model.predict(X)[0][0])\n",
    "    \n",
    "    if prediction == 1: \n",
    "        arr = np.array(X.reshape(106,106),dtype = np.uint8);\n",
    "        arr*= 255;\n",
    "        new_image = Image.fromarray(arr,'L')\n",
    "        plt.figure(); \n",
    "        plt.imshow(new_image);\n",
    "        new_image.save('04_21_attempt_2_classical_music_input_are_transformed_songs_10_epochs_OutputNumber_' + str(number_images) + '.png')\n",
    "        number_images += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f426f3",
   "metadata": {},
   "source": [
    "# 7. Save model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('04-21-classical-music-generator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75aa26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_model.save('04-21-classical-music-generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c0cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-21-classical-music-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2650575",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model.save('04-21-classical-music-discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1e9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-21-classical-music-full-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46835a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_model.save('04-21-classical-music-full-gan.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b82292",
   "metadata": {},
   "source": [
    "# 8. Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10210d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9d7b5f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image2midi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-9a85fc028daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage2midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'04_16_attempt_1_classical_music_10_epochs_OutputNumber_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'image2midi' is not defined"
     ]
    }
   ],
   "source": [
    "# ex = 0; \n",
    "# image2midi('04_16_attempt_1_classical_music_10_epochs_OutputNumber_' + str(ex) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
